{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "## ------ CREATE MOVES INPUT FILE ------ ##\n",
    "#   Tim O'Leary 2023/10/3\n",
    "#   Script borrows from original SAS script 'create.moves.input.file.imversion.sas',\n",
    "#   originally written by Craig Heither.\n",
    "#   Script reads model output generated by punchmoves.py and formats it for input into \n",
    "#   MOVES. Two spreadsheets are created:\n",
    "#     - one containing data for the Vehicle Inspection and Maintenance area in the IL portion of the non-attainment area.\n",
    "#     - one containing data for the non-Vehicle Inspection and Maintenance area in the IL portion of the non-attainment area.\n",
    "# ---------------------------------------\n",
    "#\n",
    "# MOVES Data Conversion Dictionary:\n",
    "#\n",
    "#     Road Types:\n",
    "#         MOVES Type & Description                  Model VDF\n",
    "#         -----------------------------             ---------------\n",
    "#          1: Off-Network                     -     N/A\n",
    "#          2: Rural Restricted Access         -     rural 2,3,4,5,7,8\n",
    "#          3: Rural Unrestricted Access       -     rural 1,6\n",
    "#          4: Urban Restricted Access         -     urban 2,3,4,5,7,8\n",
    "#          5: Urban Unrestricted Access       -     urban 1,6\n",
    "#\n",
    "#     Source Types:\n",
    "#         MOVES Type & Description                  HPMS Type & Description                 VHT Distribution Source from model\n",
    "#         -----------------------------             -------------------------               ----------------------------------\n",
    "#          11: Motorcycle                     -     10: Motorcycles                    -    (use auto distribution)\n",
    "#          21: Passenger Car                  -     20: Passenger Cars                 -    autos\n",
    "#          31: Passenger Truck                -     30: Other 2 axle-4 tire vehicles   -    autos\n",
    "#          32: Light Commercial Truck         -     30: Other 2 axle-4 tire vehicles   -    b-plates\n",
    "#          41: Intercity Bus                  -     40: Buses                          -    (use transit bus distribution)\n",
    "#          42: Transit Bus                    -     40: Buses                          -    transit bus\n",
    "#          43: School Bus                     -     40: Buses                          -    (use transit bus distribution)\n",
    "#          51: Refuse Truck                   -     50: Single Unit Trucks             -    (use medium duty trucks under 200 miles distribution)\n",
    "#          52: Single Unit Short-haul Truck   -     50: Single Unit Trucks             -    light trucks + medium duty trucks under 200 miles\n",
    "#          53: Single Unit Long-haul Truck    -     50: Single Unit Trucks             -    medium duty trucks 200+ miles\n",
    "#          54: Motor Home                     -     50: Single Unit Trucks             -    (use medium duty trucks 200+ miles distribution)\n",
    "#          61: Combination Short-haul Truck   -     60: Combination Trucks             -    heavy duty trucks under 200 miles\n",
    "#          62: Combination Long-haul Truck    -     60: Combination Trucks             -    heavy duty trucks 200+ miles\n",
    "\n",
    "\n",
    "## ------ IMPORT MODULES ------ ##\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd, numpy as np\n",
    "import datetime as dt\n",
    "import openpyxl\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "## ------ PARAMETERS ------ ##\n",
    "workspace = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "#get model version and scenario year - for output filenames\n",
    "#looks for a string of the form 'c??q?_?00' where '?' is any numerical digit\n",
    "model_year = re.findall(r'c\\d{2}q\\d{1}_\\d{1}00',workspace)  #e.g., 'c23q4_400'\n",
    "model = model_year[0][0:5]                                  # e.g., 'c23q4'\n",
    "scenyear = model_year[0][-3:]                               # e.g., '400'\n",
    "\n",
    "#bring in punch moves link data\n",
    "linkdata = pd.read_csv(workspace + '\\\\Database\\\\data\\\\punchlink.csv')\n",
    "\n",
    "#output excel worksheets\n",
    "excel_file_IM = workspace + f'\\\\Database\\\\data\\\\MOVES_{model}_scen{scenyear}_IM.xlsx'\n",
    "excel_file_noIM = workspace + f'\\\\Database\\\\data\\\\MOVES_{model}_scen{scenyear}_nonIM.xlsx'\n",
    "\n",
    "##create excel workbook to write worksheets to\n",
    "xlsx_IM = pd.ExcelWriter(excel_file_IM)\n",
    "xlsx_noIM = pd.ExcelWriter(excel_file_noIM)\n",
    "\n",
    "\n",
    "## ------ CLEAN-UP DATASET ------ ##\n",
    "\n",
    "#clean up column names\n",
    "collist = linkdata.columns.tolist()\n",
    "cols_to_rename = [a for a in collist if a.startswith('@')]\n",
    "coldict = dict([[a, a[1:]] for a in cols_to_rename])\n",
    "coldict['tmpl2'] = 'isramp'\n",
    "linkdata.rename(columns=coldict, inplace=True)\n",
    "\n",
    "#column data types\n",
    "for x in ['i_node', 'j_node', 'timeperiod', 'lan', 'vdf', 'zone', 'imarea', 'atype']:\n",
    "    linkdata[x] = linkdata[x].astype(int)\n",
    "for x in ['len', 'emcap', 'timau', 'ftime', 'avauv', 'avh2v', 'avh3v', 'avbqv', 'avlqv',\n",
    "          'avmqv', 'avhqv', 'atype', 'busveq']:\n",
    "    linkdata[x] = linkdata[x].astype(float)\n",
    "\n",
    "#flag ramp links\n",
    "linkdata.loc[linkdata['vdf'].isin([3,5,8]),'isramp']=1\n",
    "\n",
    "#include only non-attainment zones\n",
    "na_zones = [\n",
    "    list(range(1,2305)),\n",
    "    list(range(2309,2314)),\n",
    "    list(range(2317,2320)),\n",
    "    list(range(2326,2927)),\n",
    "    [2941,2943,2944,2949]\n",
    "]\n",
    "\n",
    "na_zones = [item for sublist in na_zones for item in sublist]\n",
    "links = linkdata.loc[linkdata['zone'].isin(na_zones)].copy()\n",
    "\n",
    "\n",
    "## ------ LINK CALCULATIONS ------ ##\n",
    "\n",
    "# reset total mtruck/htruck veh equivalents to short-haul veh equivalents\n",
    "links['m200'] = np.minimum(links['m200'], links['avmqv'])      # m200 cannot exceed final MSA balanced volau\n",
    "links['avmqv'] = np.maximum(links['avmqv']-links['m200'], 0)   # now only short haul\n",
    "links['h200'] = np.minimum(links['h200'], links['avhqv'])      # h200 cannot exceed final MSA balanced volau\n",
    "links['avhqv'] = np.maximum(links['avhqv']-links['h200'], 0)   # now only short haul\n",
    "\n",
    "#total volume in vehicle equivalents\n",
    "links.eval('volau = avauv + avh2v + avh3v + avbqv + avlqv + avmqv + m200 + avhqv + h200 + busveq', inplace=True)\n",
    "\n",
    "# volume in # vehicles (for VMT/VHT)\n",
    "links['sov'] = np.maximum(links['avauv'],0)\n",
    "links['hov2'] = np.maximum(links['avh2v'],0)\n",
    "links['hov3'] = np.maximum(links['avh3v'],0)\n",
    "links.eval('auto = sov + hov2 + hov3', inplace=True)\n",
    "links['bplate'] = np.maximum(links['avbqv'],0)\n",
    "links['ltruck'] = np.maximum(links['avlqv'],0)\n",
    "links['mtruck'] = np.maximum(links['avmqv']/2,0)\n",
    "links.eval('sush = ltruck + mtruck', inplace=True)\n",
    "links['htruck'] = np.maximum(links['avhqv']/3,0)\n",
    "links['bus'] = np.maximum(links['busveq']/3,0)\n",
    "links['mtrucklh'] = np.maximum(links['m200']/2,0)\n",
    "links['htrucklh'] = np.maximum(links['h200']/3,0)\n",
    "links.eval('vehicles = auto + bplate + sush + mtrucklh + htruck + htrucklh + bus', inplace=True)\n",
    "\n",
    "##link capacity calculations \n",
    "\n",
    "# lines 230-234\n",
    "# number of hrs per time period (for capacity calcs)\n",
    "hours = {1:5, 2:1, 3:2, 4:1, 5:4, 6:2, 7:2, 8:2} ## dict format => {'timeperiod': 'number of hours'}\n",
    "links['hours'] = links['timeperiod'].map(hours)\n",
    "links.eval('capacity = lan * emcap * hours', inplace=True)\n",
    "\n",
    "# lines 238-243\n",
    "# arterial speed adjustment due to LOS C used in VDF (for VHT calculations)\n",
    "links['fmph'] = np.where((links['ftime'] > 0), (links['len']/(links['ftime']/60)), 20)\n",
    "links['mph'] = np.where((links['timau'] > 0), (links['len']/(links['timau']/60)), 20)\n",
    "## - NOTE: old SAS script used minimum of 0 mph. this has no difference computationally (already adjusted in model)\n",
    "\n",
    "# congested speed calc\n",
    "#links.loc[(links['vdf'] == 1), 'mph'] = links['fmph'] * (1/((np.log(links['fmph']) * 0.249) + 0.153 * (links['volau'] / (links['capacity']*0.75))**3.98))\n",
    "links['mph'] = np.where(links['vdf']==1, links['fmph'] * (1/((np.log(links['fmph'])*0.249)+0.153*(links['volau']/(links['capacity']*0.75))**3.98)), links['mph'])\n",
    "\n",
    "## -- Vehicle Miles Traveled and Vehicle Hours Traveled \n",
    "\n",
    "#vehicle types to be calculated\n",
    "vehicle_cols = [\n",
    "    'sov', 'hov2', 'hov3', 'auto', 'bplate', 'ltruck', \n",
    "    'mtruck', 'sush', 'htruck', 'bus', 'mtrucklh', 'htrucklh'\n",
    "]\n",
    "\n",
    "#vmt\n",
    "for c in vehicle_cols:\n",
    "    links.eval(f'{c}_vmt = {c} * len', inplace=True)\n",
    "links.eval('all_vmt = vehicles * len', inplace=True)\n",
    "\n",
    "#vht\n",
    "for c in vehicle_cols:\n",
    "    links[f'{c}_vht'] = np.where((links['mph'] > 0), links[f'{c}_vmt']/links['mph'], 0)\n",
    "links['all_vht'] = np.where((links['mph'] > 0), links['all_vmt']/links['mph'], 0)\n",
    "\n",
    "\n",
    "## -- Setup MOVES variables \n",
    "#create avgSpeedBinID by reclassifying mph\n",
    "def speed_class(mph):\n",
    "    if mph < 2.5:\n",
    "        return 1\n",
    "    elif mph < 7.5:\n",
    "        return 2\n",
    "    elif mph < 12.5:\n",
    "        return 3\n",
    "    elif mph < 17.5:\n",
    "        return 4\n",
    "    elif mph < 22.5:\n",
    "        return 5\n",
    "    elif mph < 27.5:\n",
    "        return 6\n",
    "    elif mph < 32.5:\n",
    "        return 7\n",
    "    elif mph < 37.5:\n",
    "        return 8\n",
    "    elif mph < 42.5:\n",
    "        return 9\n",
    "    elif mph < 47.5:\n",
    "        return 10\n",
    "    elif mph < 52.5:\n",
    "        return 11\n",
    "    elif mph < 57.5:\n",
    "        return 12\n",
    "    elif mph < 62.5:\n",
    "        return 13\n",
    "    elif mph < 67.5:\n",
    "        return 14\n",
    "    elif mph < 72.5:\n",
    "        return 15\n",
    "    else:\n",
    "        return 16\n",
    "links['avgSpeedBinID'] = links['mph'].map(speed_class)\n",
    "\n",
    "#create facility types\n",
    "#for vdf = 1 or 6\n",
    "links.loc[(links['vdf'].isin([1,6]))&(links['atype']<9), 'roadTypeID']=5 #urban arterial\n",
    "links.loc[(links['vdf'].isin([1,6]))&~(links['atype']<9), 'roadTypeID']=3 #rural arterial\n",
    "# for vdf != 1 or 6\n",
    "links.loc[~(links['vdf'].isin([1,6]))&(links['atype']<9), 'roadTypeID']=4 #urban freeway\n",
    "links.loc[~(links['vdf'].isin([1,6]))&~(links['atype']<9), 'roadTypeID']=2 #rural freeway\n",
    "\n",
    "\n",
    "## ------ Create MOVES 'initial_model_output' Table ------ ##\n",
    "\n",
    "#line 305\n",
    "#grab columns we want to aggregate\n",
    "b1_columns = [[f'{c}_vmt', f'{c}_vht'] for c in ['auto','bplate','sush','mtrucklh','htrucklh','htruck','bus']]\n",
    "b1_columns = [a for sublist in b1_columns for a in sublist]\n",
    "aggsums = {}\n",
    "for a in b1_columns:\n",
    "    aggsums[a] = 'sum'\n",
    "\n",
    "groupcols = ['imarea', 'roadTypeID', 'timeperiod', 'avgSpeedBinID', 'hours']\n",
    "\n",
    "b1 = links.groupby(groupcols).agg(aggsums).reset_index()\n",
    "\n",
    "# #vmt verification\n",
    "# #line 308-313\n",
    "\n",
    "# print('Totals Before')\n",
    "# links.groupby(['imarea']).agg(aggsums)\n",
    "#disaggregate to hourly data\n",
    "#lines 316-324\n",
    "\n",
    "#timeperiod = 1 is 10 hours, others are still fine\n",
    "b1.loc[b1['timeperiod']==1, 'hours']=10\n",
    "\n",
    "#changing values to be normalized by # hours in timeperiod\n",
    "for c in b1_columns:\n",
    "    b1.eval(f'{c} = {c} / hours', inplace=True)\n",
    "\n",
    "\n",
    "#we need to duplicate each row to include each hour-of-day value\n",
    "#will do this by appending rows to a new dataframe using some dictionaries\n",
    "\n",
    "#this sets up hour of day, will call this below\n",
    "times = {1:[21,22,23,24,1,2,3,4,5,6], \n",
    "         2:[7], \n",
    "         3:[8,9], \n",
    "         4:[10], \n",
    "         5:[11,12,13,14], \n",
    "         6:[15,16],\n",
    "         7:[17,18],\n",
    "         8:[19,20]\n",
    "        }\n",
    "\n",
    "#create new df of each timeperiod\n",
    "b1_dfs = []\n",
    "for tp in times:\n",
    "    b_tp = b1.loc[b1['timeperiod']==tp].copy(deep=True)\n",
    "    #create new df for each hour-of-day within each timeperiod, then append to b1_dfs as an item in list\n",
    "    for hour in times[tp]:\n",
    "        bb = b_tp.copy(deep=True)\n",
    "        bb['hr'] = hour\n",
    "        b1_dfs.append(bb)\n",
    "\n",
    "#concatenate all timeperiod dataframes in b1_dfs into one df\n",
    "b1 = pd.concat(b1_dfs, ignore_index=True)\n",
    "b1['hourDayID'] = b1['hr']*10+5     #'5' indicates a weekday'\n",
    "b1.sort_values(['imarea','roadTypeID','avgSpeedBinID','timeperiod','hourDayID'], inplace=True)\n",
    "\n",
    "#need to make separate rows for vmt/vht of each vehicle class\n",
    "#will do this by creating a separate df for each vehicle class, then recombine\n",
    "\n",
    "common_columns = ['roadTypeID', 'timeperiod', 'avgSpeedBinID', 'hourDayID', 'imarea']\n",
    "#passenger car - 21\n",
    "b2 = b1[common_columns + ['auto_vmt', 'auto_vht']].copy().rename(columns={'auto_vmt':'vmt', 'auto_vht':'vht'})\n",
    "b2['sourceTypeID'] = 21\n",
    "#passenger truck - 31\n",
    "b3 = b1[common_columns + ['auto_vmt', 'auto_vht']].copy().rename(columns={'auto_vmt':'vmt', 'auto_vht':'vht'})\n",
    "b3['sourceTypeID'] = 31\n",
    "#light commercial truck - 32\n",
    "b4 = b1[common_columns + ['bplate_vmt', 'bplate_vht']].copy().rename(columns={'bplate_vmt':'vmt', 'bplate_vht':'vht'})\n",
    "b4['sourceTypeID'] = 32\n",
    "#SU short haul truck - 52\n",
    "b5 = b1[common_columns + ['sush_vmt', 'sush_vht']].copy().rename(columns={'sush_vmt':'vmt', 'sush_vht':'vht'})\n",
    "b5['sourceTypeID'] = 52\n",
    "#SU long-haul truck - 53\n",
    "b6 = b1[common_columns + ['mtrucklh_vmt', 'mtrucklh_vht']].copy().rename(columns={'mtrucklh_vmt':'vmt', 'mtrucklh_vht':'vht'})\n",
    "b6['sourceTypeID'] = 53\n",
    "#MU short haul - 61\n",
    "b7 = b1[common_columns + ['htruck_vmt', 'htruck_vht']].copy().rename(columns={'htruck_vmt':'vmt', 'htruck_vht':'vht'})\n",
    "b7['sourceTypeID'] = 61\n",
    "#MU long haul - 62\n",
    "b8 = b1[common_columns + ['htrucklh_vmt', 'htrucklh_vht']].copy().rename(columns={'htrucklh_vmt':'vmt', 'htrucklh_vht':'vht'})\n",
    "b8['sourceTypeID'] = 62\n",
    "#transit bus - 42\n",
    "b9 = b1[common_columns + ['bus_vmt', 'bus_vht']].copy().rename(columns={'bus_vmt':'vmt', 'bus_vht':'vht'})\n",
    "b9['sourceTypeID'] = 42\n",
    "#intercity bus - 41 -- apply transit bus distribution to intercity bus\n",
    "b10 = b9.copy()\n",
    "b10['sourceTypeID'] = 41\n",
    "#school bus - 43 -- apply transit bus distribution to school bus\n",
    "b11 = b9.copy()\n",
    "b11['sourceTypeID'] = 43\n",
    "#motorcycle - 11 -- apply auto distribution to motorcycles\n",
    "b12 = b2.copy()\n",
    "b12['sourceTypeID'] = 11\n",
    "#refuse trucks - 51 -- apply single unit short-haul distribution to refuse trucks\n",
    "b13 = b5.copy()\n",
    "b13['sourceTypeID'] = 51\n",
    "#motor homes - 54 -- apply single unit long-haul distribution to motor homes\n",
    "b14 = b6.copy()\n",
    "b14['sourceTypeID'] = 54\n",
    "\n",
    "b = pd.concat([b2, b3, b4, b5, b6, b7, b8, b9, b10, b11, b12, b13, b14], ignore_index=True)\n",
    "b.sort_values(['imarea', 'sourceTypeID', 'roadTypeID', 'hourDayID', 'avgSpeedBinID'], inplace=True)\n",
    "\n",
    "\n",
    "#need to apply values onto a template that contains all possible combinations\n",
    "#create template with all combinations\n",
    "#line 369-374\n",
    "\n",
    "#get unique values for each of the categories: sourceTypeID, roadTypeID, hourDayID, avgSpeedBinID, and imarea\n",
    "veh = b['sourceTypeID'].unique().tolist()\n",
    "road = b['roadTypeID'].unique().tolist()\n",
    "hrday = b['hourDayID'].unique().tolist()\n",
    "speed = b['avgSpeedBinID'].unique().tolist()\n",
    "imcat = b['imarea'].unique().tolist()\n",
    "\n",
    "#create cartesian product of the lists listed above\n",
    "template_values = list(product(veh, road, hrday, speed, imcat))\n",
    "template = pd.DataFrame(template_values, columns=['sourceTypeID', 'roadTypeID', 'hourDayID', 'avgSpeedBinID', 'imarea'])\n",
    "template.sort_values(['imarea', 'sourceTypeID', 'roadTypeID', 'hourDayID', 'avgSpeedBinID'], inplace=True)\n",
    "template.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#merge data with template\n",
    "b = pd.merge(template, b, how='left', on=['imarea', 'sourceTypeID', 'roadTypeID', 'hourDayID', 'avgSpeedBinID'])\n",
    "# b.fillna(0, inplace=True) #remove null values\n",
    "b.drop(columns='timeperiod', inplace=True)\n",
    "\n",
    "#remove negative vmt/vht values, if they exist, or fill with zeroes\n",
    "def replace_neg_w_zero(x):\n",
    "    return max(0,x)\n",
    "b['vmt'] = b['vmt'].apply(replace_neg_w_zero)\n",
    "b['vht'] = b['vht'].apply(replace_neg_w_zero)\n",
    "\n",
    "\n",
    "#####################################\n",
    "## -- INIITIAL MODEL OUTPUT TAB -- ##\n",
    "#####################################\n",
    "#line 462-473\n",
    "#only include source types from actual modeled vehicle trips -- for QC\n",
    "\n",
    "#initial_model_output tab in excel file\n",
    "#imarea\n",
    "outIM_initialmodeloutput = b.loc[~(b['sourceTypeID'].astype('int').isin([11,41,43,51,54]))&(b['imarea']==1)].copy(deep=True)\n",
    "outIM_initialmodeloutput.to_excel(xlsx_IM, sheet_name='initial_model_output', index=False)\n",
    "\n",
    "#non-imarea\n",
    "outnoIM_initialmodeloutput = b.loc[~(b['sourceTypeID'].astype('int').isin([11,41,43,51,54]))&(b['imarea']==0)].copy(deep=True)\n",
    "outnoIM_initialmodeloutput.to_excel(xlsx_noIM, sheet_name='initial_model_output', index=False)\n",
    "\n",
    "\n",
    "##################################\n",
    "## -- SPEED DISTRIBUTION TAB -- ##\n",
    "##################################\n",
    "\n",
    "#lines 479-482\n",
    "#CALCULATE VHT SHARE BY SOURCETYPEID-ROADTYPEID-HOURDAYID\n",
    "#then join back to table\n",
    "\n",
    "casecols = ['imarea', 'sourceTypeID', 'roadTypeID', 'hourDayID']\n",
    "\n",
    "sumvht = b.groupby(casecols).agg({'vht':'sum'})\n",
    "sumvht.rename(columns={'vht':'allvht'}, inplace=True)\n",
    "sumvht.reset_index(inplace=True)\n",
    "share = pd.merge(b, sumvht, on=casecols, how='inner')\n",
    "\n",
    "\n",
    "#lines 485-512\n",
    "# -- USE SURROGATES TO REPLACE MISSING VALUES -- \n",
    "\n",
    "#bus, pt 1: use roadTypeID 4 to replace missing values for roadTypeID 2 for sourceTypeID 41,42,43 for IM area\n",
    "fb1_a = share.loc[(share['sourceTypeID']==42)&(share['roadTypeID']==4)&(share['imarea']==1)].copy(deep=True)\n",
    "fb1_a['roadTypeID'] = 2\n",
    "fb1_b = fb1_a.copy()\n",
    "fb1_b['sourceTypeID'] = 41\n",
    "fb1_c = fb1_a.copy()\n",
    "fb1_c['sourceTypeID'] = 43\n",
    "fb1 = pd.concat([fb1_a, fb1_b, fb1_c])\n",
    "\n",
    "#bus, pt2: use sourceTypeID 41,42,43 for IM area to replace missing values for non-IM area\n",
    "fb2 = pd.concat([fb1, share.loc[(share['sourceTypeID'].isin([41,42,43]))&(share['imarea']==1)].copy(deep=True)])\n",
    "fb2['imarea']=0\n",
    "\n",
    "#SU long-haul truck, pt1: use sourceTypeID 52 to replace missing values for sourceTypeID 53,54 for IM area\n",
    "fb3 = share.loc[(share['sourceTypeID']==52)&(share['imarea']==1)].copy(deep=True)\n",
    "fb3_a = fb3.copy()\n",
    "fb3_a['sourceTypeID'] = 53\n",
    "fb3_b = fb3.copy()\n",
    "fb3_b['sourceTypeID'] = 54\n",
    "fb3 = pd.concat([fb3_a, fb3_b])\n",
    "\n",
    "#SU long-haul truck, pt2: use sourceTypeID 52,53,54 for IM area to replace missing values for non-IM area\n",
    "fb4 = pd.concat([fb3, share.loc[(share['sourceTypeID']==52)&(share['imarea']==1)]], ignore_index=True)\n",
    "fb4['imarea'] = 0\n",
    "\n",
    "#MU long-haul truck pt1: use sourceTypeID 61 to replace missing values for sourceTypeID 62 for IM area\n",
    "fb5 = share.loc[(share['sourceTypeID']==61)&(share['imarea']==1)].copy(deep=True)\n",
    "fb5['sourceTypeID'] = 62\n",
    "\n",
    "#MU long-haul truck pt2: use sourceTypeID 61, 62 for IM area to replace missing values for non-IM area\n",
    "fb6 = pd.concat([fb5, share.loc[(share['sourceTypeID']==61)&(share['imarea']==1)].copy(deep=True)])\n",
    "fb6['imarea'] = 0\n",
    "\n",
    "#combining this whole mess together\n",
    "fallback = pd.concat([fb1, fb2, fb3, fb4, fb5, fb6], ignore_index=True)\n",
    "fallback.rename(columns={'vht':'vht2', 'allvht':'allvht2'}, inplace=True)\n",
    "fallback.drop(columns='vmt', inplace=True)\n",
    "fallback.drop_duplicates(['imarea', 'sourceTypeID', 'roadTypeID', 'hourDayID', 'avgSpeedBinID'], inplace=True)\n",
    "fallback.sort_values(['imarea', 'sourceTypeID', 'roadTypeID', 'hourDayID', 'avgSpeedBinID'], inplace=True)\n",
    "\n",
    "share = pd.merge(share, fallback, how='left', on=['imarea', 'sourceTypeID', 'roadTypeID', 'hourDayID', 'avgSpeedBinID'])\n",
    "share.loc[(share['allvht']==0)&~(share['allvht2'].isnull()), 'vht'] = share['vht2']\n",
    "share.loc[(share['allvht']==0)&~(share['allvht2'].isnull()), 'allvht'] = share['allvht2']\n",
    "share.eval('avgSpeedFraction = vht / allvht', inplace=True)\n",
    "\n",
    "\n",
    "## -- AvgSpeedDistribution excel sheet -- ##\n",
    "\n",
    "avg_speed_dist = share[['imarea', 'sourceTypeID', 'roadTypeID', 'hourDayID', 'avgSpeedBinID','avgSpeedFraction']]\n",
    "\n",
    "outIM_avgspeeddistribution = avg_speed_dist.loc[(avg_speed_dist['imarea']==1)].drop(columns='imarea')\n",
    "outIM_avgspeeddistribution.to_excel(xlsx_IM, sheet_name='AvgSpeedDistribution', index=False)\n",
    "\n",
    "outnoIM_avgspeeddistribution = avg_speed_dist.loc[(avg_speed_dist['imarea']==0)].drop(columns='imarea')\n",
    "outnoIM_avgspeeddistribution.to_excel(xlsx_noIM, sheet_name='AvgSpeedDistribution', index=False)\n",
    "\n",
    "\n",
    "######################################\n",
    "## -- road type distribution tab -- ##\n",
    "######################################\n",
    "\n",
    "roadtype = b.groupby(['imarea','sourceTypeID','roadTypeID']).agg({'vmt':'sum'}).reset_index()\n",
    "roadtype2 = b.groupby(['imarea','sourceTypeID']).agg({'vmt':'sum'}).rename(columns={'vmt':'sourceVMT'}).reset_index()\n",
    "\n",
    "roadtype = pd.merge(roadtype, roadtype2, how='left', on=['imarea','sourceTypeID'])\n",
    "\n",
    "#ensure correct datatypes\n",
    "for f in ['sourceTypeID', 'roadTypeID', 'imarea']:\n",
    "    roadtype[f] = roadtype[f].astype('int')\n",
    "for f in ['vmt','sourceVMT']:\n",
    "    roadtype[f] = roadtype[f].astype('float')\n",
    "\n",
    "\n",
    "# -- use surrogates to replace missing values if necessary\n",
    "\n",
    "#bus part1: use roadTypeID 4 to replace missing values for roadTypeID 2 for sourceTypeID 41,42,43 for IM area\n",
    "fb1 = roadtype.loc[(roadtype['sourceTypeID']==42)&(roadtype['roadTypeID']==4)&(roadtype['imarea']==1)].copy(deep=True)\n",
    "fb1_a = fb1.copy()\n",
    "fb1_a['roadTypeID'] = 2\n",
    "fb1_b = fb1_a.copy()\n",
    "fb1_b['sourceTypeID'] = 41\n",
    "fb1_c = fb1_b.copy()\n",
    "fb1_c['sourceTypeID'] = 43\n",
    "fb1 = pd.concat([fb1_a, fb1_b, fb1_c], ignore_index=True)\n",
    "\n",
    "#bus part2: use sourcetypeID 41, 42, 43 for IM area to replace missing values for non-IM area\n",
    "fb2 = pd.concat([fb1, roadtype.loc[(roadtype['sourceTypeID'].isin([41,42,43]))&(roadtype['imarea']==1)].copy(deep=True)], ignore_index=True)\n",
    "fb2['imarea'] = 0\n",
    "\n",
    "#SU long-haul truck part1: use sourcetypeID 52 to replace missing values for sourceTypeID 53,54 for IM area\n",
    "fb3 = roadtype.loc[(roadtype['sourceTypeID']==52)&(roadtype['imarea']==1)].copy(deep=True)\n",
    "fb3_a = fb3.copy()\n",
    "fb3_a['sourceTypeID'] = 53\n",
    "fb3_b = fb3_a.copy()\n",
    "fb3_b['sourceTypeID'] = 54\n",
    "fb3 = pd.concat([fb3_a, fb3_b], ignore_index=True)\n",
    "\n",
    "#SU long-hault truck part2: use sourcetypeID 52. 53. 54 for IM area to replace missing values for non-IM area\n",
    "fb4 = pd.concat([fb3, roadtype.loc[(roadtype['sourceTypeID']==52)&roadtype['imarea']==1].copy(deep=True)])\n",
    "fb4['imarea']=0\n",
    "\n",
    "#MU long-haul truck part1: use sourceTypeID 61 to replace missing values for sourcetypeID 62 for IM area\n",
    "fb5 = roadtype.loc[(roadtype['sourceTypeID']==61)&(roadtype['imarea']==1)].copy(deep=True)\n",
    "fb5['sourceTypeID'] = 62\n",
    "\n",
    "#MU long-haul truck part2: use sourceTypeID 61,62 for IM area to replace missing values for non-IM area\n",
    "fb6 = pd.concat([fb5, roadtype.loc[(roadtype['sourceTypeID']==61)&(roadtype['imarea']==1)].copy(deep=True)])\n",
    "fb6['imarea'] = 0\n",
    "\n",
    "fallback = pd.concat([fb1,fb2,fb3,fb4,fb5,fb6]).rename(columns={'vmt':'vmt2', 'sourceVMT':'sourceVMT2'}).sort_values(['imarea','sourceTypeID','roadTypeID']).drop_duplicates(['imarea','sourceTypeID','roadTypeID'])\n",
    "\n",
    "roadtype = pd.merge(roadtype, fallback, how='left', on=['imarea', 'sourceTypeID', 'roadTypeID'])\n",
    "# roadtype.loc[(roadtype['sourceVMT']==0)&~(roadtype['sourceVMT2'].isnull()), ['vmt', 'sourceVMT']] = roadtype[['vmt2', 'sourceVMT2']]\n",
    "roadtype.loc[(roadtype['sourceVMT']==0)&~(roadtype['sourceVMT2'].isnull()), 'vmt'] = roadtype['vmt2']\n",
    "roadtype.loc[(roadtype['sourceVMT']==0)&~(roadtype['sourceVMT2'].isnull()), 'sourceVMT'] = roadtype['sourceVMT2']\n",
    "\n",
    "#prevent division by zero\n",
    "def abovezero(x):\n",
    "    return np.maximum(x,0.000001)\n",
    "roadtype['sourceVMT'] = roadtype['sourceVMT'].apply(abovezero)\n",
    "\n",
    "roadtype.eval('roadTypeVMTFraction = vmt / sourceVMT', inplace=True)\n",
    "roadtype['roadTypeVMTFraction'] = roadtype['roadTypeVMTFraction'].round(6)\n",
    "\n",
    "\n",
    "## -- RoadTypeDistribution excel sheet -- ##\n",
    "outIM_roadtypedistribution = roadtype.loc[roadtype['imarea']==1,['sourceTypeID','roadTypeID','roadTypeVMTFraction']].copy()\n",
    "outIM_roadtypedistribution.to_excel(xlsx_IM, sheet_name='RoadTypeDistribution', index=False)\n",
    "\n",
    "outnoIM_roadtypedistribution = roadtype.loc[(roadtype['imarea']==0),['sourceTypeID', 'roadTypeID', 'roadTypeVMTFraction']].copy()\n",
    "outnoIM_roadtypedistribution.to_excel(xlsx_noIM, sheet_name='RoadTypeDistribution', index=False)\n",
    "\n",
    "\n",
    "#############################\n",
    "## -- Ramp Fraction Tab -- ##\n",
    "#############################\n",
    "\n",
    "rmp = links.loc[links['roadTypeID'].isin([2,4])].copy(deep=True)\n",
    "rmp.eval('fwyvht = auto_vht + bplate_vht + sush_vht + mtrucklh_vht + htruck_vht + htrucklh_vht + bus_vht', inplace=True)\n",
    "rmp.eval('fwyvmt = auto_vmt + bplate_vmt + sush_vmt + mtrucklh_vmt + htruck_vmt + htrucklh_vmt + bus_vmt', inplace=True)\n",
    "rmp['rampvht'] = np.where(rmp['isramp']==1, rmp['fwyvht'], 0)\n",
    "rmp['rampvmt'] = np.where(rmp['isramp']==1, rmp['fwyvmt'], 0)\n",
    "\n",
    "ramp = rmp.groupby(['imarea','roadTypeID']).agg({'fwyvht':'sum','rampvht':'sum','fwyvmt':'sum','rampvmt':'sum'}).reset_index()\n",
    "ramp.eval('rampFraction = rampvht/fwyvht', inplace=True)\n",
    "ramp['rampFraction'] = ramp['rampFraction'].round(6)\n",
    "ramp.eval('vmtFraction = rampvmt/fwyvmt', inplace=True)\n",
    "ramp['vmtFraction'] = ramp['vmtFraction'].round(6)\n",
    "\n",
    "#ramp fraction to excel\n",
    "outIM_rampfraction = ramp.loc[ramp['imarea']==1,['roadTypeID','rampFraction']]\n",
    "outIM_rampfraction.to_excel(xlsx_IM, sheet_name='RampFraction', index=False)\n",
    "\n",
    "outnoIM_rampfraction = ramp.loc[(ramp['imarea']==0),['roadTypeID','rampFraction']]\n",
    "outnoIM_rampfraction.to_excel(xlsx_noIM, sheet_name='RampFraction', index=False)\n",
    "\n",
    "\n",
    "###################################\n",
    "## -- Hourly VMT Fraction Tab -- ##\n",
    "###################################\n",
    "\n",
    "#create template of all combos -- sourceTypeID, roadTypeID, dayID, hourID, imarea\n",
    "    #the following exist further up the script: \n",
    "        # veh = b['sourceTypeID'].unique().tolist()\n",
    "road = b['roadTypeID'].unique().tolist()\n",
    "        # hrday = b['hourDayID'].unique().tolist()\n",
    "        # imcat = b['imarea'].unique().tolist()\n",
    "\n",
    "#add roadtype 1:\n",
    "road.append(1)\n",
    "\n",
    "#create separate hrID and dayID\n",
    "hourID = []\n",
    "for item in hrday:\n",
    "    hourID.append((item - 5)/10)\n",
    "dayID = [5]\n",
    "\n",
    "#cartesian product of the lists listed above\n",
    "template_values = list(product(veh, road, hourID, dayID, imcat))\n",
    "template2 = pd.DataFrame(template_values, columns=['sourceTypeID', 'roadTypeID', 'hourID', 'dayID', 'imarea'])\n",
    "template2.sort_values(['imarea', 'sourceTypeID', 'roadTypeID', 'hourID'], inplace=True)\n",
    "vmt = b.copy()\n",
    "vmt['hourID'] = (vmt['hourDayID'] - 5)/10\n",
    "\n",
    "hourvmt = vmt.groupby(['imarea','sourceTypeID','roadTypeID','hourID']).agg({'vmt':'sum'}).reset_index()\n",
    "sumvmt = hourvmt.groupby(['imarea', 'sourceTypeID','roadTypeID']).agg({'vmt':'sum'}).reset_index()\n",
    "sumvmt.rename(columns={'vmt':'allvmt'},inplace=True)\n",
    "\n",
    "vmtshare = pd.merge(hourvmt, sumvmt, how='left', on=['imarea','sourceTypeID','roadTypeID'])\n",
    "vmtshare.sort_values(['imarea','sourceTypeID','roadTypeID','hourID'],inplace=True)\n",
    "\n",
    "\n",
    "## -- use surrogates to replace missing values, if necessary\n",
    "\n",
    "#bus part 1: use sourcetypeid 42 to replace missing values for sourceTypeID 41,43 for IM area\n",
    "fb1 = vmtshare.loc[(vmtshare['sourceTypeID']==42)&(vmtshare['imarea']==1)].copy()\n",
    "fb1_a = fb1.copy()\n",
    "fb1_a['sourceTypeID'] = 41\n",
    "fb1_b = fb1.copy()\n",
    "fb1_b['sourceTypeID'] = 43\n",
    "fb1 = pd.concat([fb1_a, fb1_b], ignore_index=True)\n",
    "\n",
    "#bus part2: use sourcetypeID 41,42,43 for IM area to replace missing values for non-IM area\n",
    "fb2 = pd.concat([fb1, vmtshare.loc[(vmtshare['sourceTypeID'].isin([41,42,43]))&(vmtshare['imarea']==1)&(vmtshare['allvmt']>0)].copy()], ignore_index=True)\n",
    "fb2['imarea'] = 0\n",
    "\n",
    "#su long-haul truck part1: use sourceTypeID 52 to replace missing values for sourcetypeID 53,54 for im area\n",
    "fb3 = vmtshare.loc[(vmtshare['sourceTypeID']==52)&(vmtshare['imarea']==1)].copy()\n",
    "fb3_a = fb3.copy()\n",
    "fb3_a['sourceTypeID'] = 53\n",
    "fb3_b = fb3.copy()\n",
    "fb3_b['sourceTypeID'] = 54\n",
    "fb3 = pd.concat([fb3_a, fb3_b], ignore_index=True)\n",
    "\n",
    "#su long haul truck part2: use sourceTypeID 52,53,54 for IM area to replace missing values for non-IM area\n",
    "fb4 = pd.concat([fb3, vmtshare.loc[(vmtshare['sourceTypeID'].isin([52,53,54]))&(vmtshare['imarea']==1)&(vmtshare['allvmt']>0)].copy()], ignore_index=True)\n",
    "fb4['imarea'] = 0\n",
    "\n",
    "#mu long-haul truck part 1: use sourcetypeID 61 to replace missing values for sourcetypeid 62 for im area\n",
    "fb5 = vmtshare.loc[(vmtshare['sourceTypeID']==61)&(vmtshare['imarea']==1)].copy()\n",
    "fb5['sourceTypeID'] = 62\n",
    "\n",
    "#mu long-haul truck part2: use sourcetypeid 61,62 for IM area to replace missing values for non-IM area\n",
    "fb6 = pd.concat([fb5, vmtshare.loc[(vmtshare['sourceTypeID'].isin([61,62]))&(vmtshare['imarea']==1)&(vmtshare['allvmt']>0)].copy()],ignore_index=True)\n",
    "fb6['imarea'] = 0\n",
    "\n",
    "fallback = pd.concat([fb1, fb2, fb3, fb4, fb5, fb6], ignore_index=True).sort_values(['imarea','sourceTypeID','roadTypeID','hourID'])\n",
    "fallback.rename(columns={'vmt':'vmt2', 'allvmt':'allvmt2'},inplace=True)\n",
    "fallback.drop_duplicates(subset=['imarea','sourceTypeID','roadTypeID','hourID'], inplace=True)\n",
    "\n",
    "\n",
    "vmtshare = pd.merge(vmtshare, fallback, how='left', on=['imarea', 'sourceTypeID', 'roadTypeID', 'hourID'])\n",
    "\n",
    "\n",
    "#calculates hourvmtfraction based on original data\n",
    "vmtshare['hourVMTFraction1'] = np.where(vmtshare['allvmt']>0.000001, vmtshare['vmt']/vmtshare['allvmt'], vmtshare['vmt']/0.000001)\n",
    "#calculates hourvmtfraction based on fallback data\n",
    "vmtshare.loc[~(vmtshare['vmt2'].isnull())&~(vmtshare['allvmt2'].isnull()), 'hourVMTFraction2'] = vmtshare['vmt2'] / vmtshare['allvmt2']\n",
    "\n",
    "\n",
    "#for sourcetypes 53,54 if there is any data\n",
    "#then use both the non-zero vmt and the fallback data to arrive at the hourVMTFraction\n",
    "\n",
    "truckpart = vmtshare.loc[(vmtshare['sourceTypeID'].isin([53,54]))&(vmtshare['vmt']>0)].copy()\n",
    "vmtcount = truckpart.groupby(['imarea','sourceTypeID','roadTypeID']).agg({'vmt':'count'}).reset_index()\n",
    "vmtcount.rename(columns={'vmt':'vmtcount1'},inplace=True)\n",
    "\n",
    "\n",
    "vmtweight = pd.merge(vmtshare, vmtcount, how='left', on=['imarea', 'sourceTypeID', 'roadTypeID'])\n",
    "vmtweight2 = vmtweight.copy()\n",
    "#use fallback vmtfraction for 0 vmt hours\n",
    "vmtweight2.loc[(vmtweight2['sourceTypeID'].isin([53,54]))&(vmtweight2['allvmt']>0)&(vmtweight2['vmt']==0), 'hourVMTFractionpre'] = vmtweight2['hourVMTFraction2']\n",
    "\n",
    "#use average of the original and fallback vmtfraction otherwise\n",
    "#original data is weighted by number of hours with data\n",
    "vmtweight2.loc[(vmtweight2['sourceTypeID'].isin([53,54]))&(vmtweight2['allvmt']>0)&(vmtweight2['vmt']>0), 'hourVMTFractionpre'] = (((vmtweight2['vmtcount1']/24)*vmtweight2['hourVMTFraction1'])+vmtweight2['hourVMTFraction2'])/((vmtweight2['vmtcount1']+24)/24)\n",
    "\n",
    "\n",
    "vmtpre = vmtweight2.groupby(['imarea','sourceTypeID','roadTypeID']).agg({'hourVMTFractionpre':'sum'}).reset_index()\n",
    "vmtpre.rename(columns={'hourVMTFractionpre':'vmtpresum'},inplace=True)\n",
    "\n",
    "\n",
    "vmtshare = pd.merge(vmtweight2, vmtpre, how='left', on=['imarea','sourceTypeID','roadTypeID']).sort_values(['imarea','sourceTypeID','roadTypeID','hourID'])\n",
    "vmtshare.loc[vmtshare['allvmt']==0, 'vmt3'] = vmtshare['vmt']\n",
    "vmtshare.loc[vmtshare['allvmt']==0, 'allvmt3'] = vmtshare['allvmt']\n",
    "\n",
    "\n",
    "#substitution if no VMT for entire category\n",
    "vmtshare.loc[(vmtshare['allvmt']==0)&(vmtshare['allvmt2']!=0), 'allvmt'] = vmtshare['allvmt2']\n",
    "vmtshare.loc[(vmtshare['vmt']==0)&(vmtshare['vmt2']!=0), 'vmt'] = vmtshare['vmt2']\n",
    "vmtshare.loc[((vmtshare['allvmt']==0)|(vmtshare['allvmt'].isnull()))&~(vmtshare['allvmt2'].isnull()), 'vmt'] = vmtshare['vmt2']\n",
    "vmtshare.loc[((vmtshare['allvmt']==0)|(vmtshare['allvmt'].isnull()))&~(vmtshare['allvmt2'].isnull()), 'allvmt'] = vmtshare['allvmt2']\n",
    "\n",
    "#prevent division by zero\n",
    "vmtshare['allvmt'] = np.maximum(vmtshare['allvmt'], 0.000001)\n",
    "vmtshare.eval('hourVMTFraction = vmt / allvmt', inplace=True)\n",
    "vmtshare['hourVMTFraction'] = vmtshare['hourVMTFraction'].round(6)\n",
    "\n",
    "vmtshare.loc[(vmtshare['sourceTypeID'].isin([53,54]))&(vmtshare['vmtpresum']>0), 'hourVMTFraction'] = vmtshare['hourVMTFractionpre'] / vmtshare['vmtpresum']\n",
    "vmtshare['hourVMTFractionpre'] = vmtshare['hourVMTFractionpre'].round(6)\n",
    "\n",
    "vmtshare.drop(columns=['vmtpresum','hourVMTFraction1','hourVMTFraction2','hourVMTFractionpre','vmtcount1'], inplace=True)\n",
    "\n",
    "#apply urban arterial distribution to Off-Network type\n",
    "vmtshare_b = vmtshare.copy()\n",
    "vmtshare_b.loc[vmtshare_b['roadTypeID']==5, 'roadTypeID'] = 1 \n",
    "\n",
    "vmtshare = pd.concat([vmtshare, vmtshare_b], ignore_index=True).sort_values(['imarea','sourceTypeID','roadTypeID','hourID'])\n",
    "\n",
    "vmtshare = pd.merge(template2, vmtshare, how='left', on=['imarea','sourceTypeID','roadTypeID','hourID'])\n",
    "\n",
    "vmtshare.drop_duplicates(['sourceTypeID','roadTypeID','dayID','hourID','imarea'], inplace=True)\n",
    "\n",
    "#final vmt fraction to excel\n",
    "outIM_hourvmtfraction = vmtshare.loc[vmtshare['imarea']==1, ['sourceTypeID','roadTypeID','dayID','hourID','hourVMTFraction']]\n",
    "outIM_hourvmtfraction.to_excel(xlsx_IM, sheet_name='hourVMTFraction', index=False)\n",
    "\n",
    "outnoIM_hourvmtfraction = vmtshare.loc[vmtshare['imarea']==0, ['sourceTypeID','roadTypeID','dayID','hourID','hourVMTFraction']]\n",
    "outnoIM_hourvmtfraction.to_excel(xlsx_noIM, sheet_name='hourVMTFraction', index=False)\n",
    "\n",
    "\n",
    "######################################################\n",
    "## -- VMT by road type and HPMS vehicle type tab -- ##\n",
    "######################################################\n",
    "\n",
    "#modeled vehicle types only\n",
    "hpms = b.loc[b['sourceTypeID'].isin([21,31,32,42,52,53,61,62])].copy()\n",
    "\n",
    "# key = { 'sourceTypeID' : 'HPMSVtypeID' }\n",
    "key = {\n",
    "    21:25,\n",
    "    32:25,\n",
    "    42:40, #transit bus vmt only\n",
    "    52:50,\n",
    "    53:50,\n",
    "    61:60,\n",
    "    62:60\n",
    "}\n",
    "\n",
    "hpms['HPMSVtypeID'] = hpms['sourceTypeID'].map(key)\n",
    "hpms1 = hpms.groupby(['imarea', 'roadTypeID', 'HPMSVtypeID']).agg({'vmt':'sum'}).reset_index()\n",
    "hpms1.rename(columns={'vmt':'HPMSDailyVMT'}, inplace=True)\n",
    "\n",
    "#final vmt fraction to excel\n",
    "outIM_hpmsdailyvmt = hpms1.loc[hpms1['imarea']==1, ['roadTypeID','HPMSVtypeID','HPMSDailyVMT']]\n",
    "outIM_hpmsdailyvmt['year'] = scenyear\n",
    "outIM_hpmsdailyvmt.to_excel(xlsx_IM, sheet_name='HPMSDailyVMT', index=False)\n",
    "\n",
    "outnoIM_hpmsdailyvmt = hpms1.loc[hpms1['imarea']==0, ['roadTypeID','HPMSVtypeID','HPMSDailyVMT']]\n",
    "outnoIM_hpmsdailyvmt['year'] = scenyear\n",
    "outnoIM_hpmsdailyvmt.to_excel(xlsx_noIM, sheet_name='HPMSDailyVMT', index=False)\n",
    "\n",
    "\n",
    "\n",
    "xlsx_IM.close()\n",
    "xlsx_noIM.close()\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "## ---------------- END CREATE MOVES INPUT FILE (SAS) ------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMAP-TRIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
